# CatBoost_Gini_Based_Confidence_Estimates
A method to deduce important decision rules from the CatBoost model architecture

Dataset and classification task:
University of Southern Denmark, 2023 Exam collaboration with Udvikling og Forenklingsstyrelsen (UFST). Classification task to catch Tax Fraudulent businesses in Denmark. 240 features, 2 classes. "Not tax fraudulent"=0, "Tax fraudulent"=1. Data is anonymized in accordance with GDPR. I am not allowed to describe the meaning or the definitions of the variable names. Variable names are anonymized, and so is the variable values. 

Can we consider the model competent in its ability to evaluate what is truly important for the task? 
The danger with feature based importances, SHAP values and so forth is that we implicitly expect the model to be competent. If we consider the initial classification results (see the ipynb file) we would hesitate to answer yes. It clearly does a good job predicting not fraudulent, but not so much for the fraudulent. 
But even if the model was extremely talented, I would still hesitate to call it "competent". Consider for a minute the thousands or even millions of models, of which many have tried to be implemented, but eventually failed. A great deal of those models certainly had SOTA performance, but once applied to the real world, it falls apart. Concept drift, distribution shift etc. The world is tough. Hence, it is only a small fraction of models we can truly call competent, hence, we can only conclude competency when a model is in production, and it is performing well. It is a statistical improbability that the model is competent, therefore, we can not rely on feature based importance scores alone, even SHAP values, to decide whether a feature is important or not.  

Ideally, we would traverse the Catboost model architecture, calculate the gini impurities of the leaf nodes, and then extract the associated feature splits that leads to the purest nodes. CatBoost does not provide scikit-like functionality that more easily enables one to do this (why not use Scikit you ask? well, I was way to deep with CatBoost, and i am working with both Numerical and Categorical features, so i kept at it). 

So, I propose a compromise. We use the few functionalities catboost does provide: calculate_leaf_indexes, this returns the exact leaf node each prediction i ends up in, after j-th iteration. Hence, we can access the final leaf node, calculate the class distribution and then calculate the gini impurities for the final leaf nodes. A compromise to extracting the exact feature splits in the tree of the pure nodes, then, is to use SHAP decision plots to see which features had the most impact on the most pure nodes, as given by our calculation of gini impurities. This should help us identify which features are associated with the highest quality decision rules. As one will see, by using this method, I get to debunk my "null hypothesis" that feature ejerkreds_aktiv_86 would be an important feature to help catch tax fraudulent businesses. 
